\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Module 1}{4}{chapter.1}%
\contentsline {section}{\numberline {1.1}Overview}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Giving computers the ability to learn from data}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Introduction}{4}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}The Three Different Types of Machine Learning}{5}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Supervised Learning}{5}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Classification for Predicting Class Labels}{6}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Regression for Predicting Continous Outcomes}{7}{subsection.1.3.4}%
\contentsline {section}{\numberline {1.4}Solving Problems with Reinforcement Learning}{8}{section.1.4}%
\contentsline {section}{\numberline {1.5}Unsupervised Learning}{9}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Finding Subgroups With Clustering}{9}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Dimensionality Reduction for Data Compresion}{9}{subsection.1.5.2}%
\contentsline {section}{\numberline {1.6}Terminology and Notations}{10}{section.1.6}%
\contentsline {subsection}{\numberline {1.6.1}Machine Learning Teminology}{12}{subsection.1.6.1}%
\contentsline {section}{\numberline {1.7}Machine Learning Systems}{12}{section.1.7}%
\contentsline {subsection}{\numberline {1.7.1}Preprocessing: Getting Data into Shape}{12}{subsection.1.7.1}%
\contentsline {subsection}{\numberline {1.7.2}Training and Selecting a Predictive Model}{14}{subsection.1.7.2}%
\contentsline {subsection}{\numberline {1.7.3}Evaluating Models and Predicting Unseen Data Instances}{15}{subsection.1.7.3}%
\contentsline {chapter}{\numberline {2}Training Simple Machine Learning Algorithms for Classification}{16}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{16}{section.2.1}%
\contentsline {section}{\numberline {2.2}Artificial Neurons: Early Stages of Machine Learning}{16}{section.2.2}%
\contentsline {section}{\numberline {2.3}Formal Definition of an Artificial Neuron}{17}{section.2.3}%
\contentsline {section}{\numberline {2.4}Perceptron Learning Rule}{18}{section.2.4}%
\contentsline {section}{\numberline {2.5}Implementing a Perceptron Learning Algorithm in Python}{20}{section.2.5}%
\contentsline {section}{\numberline {2.6}And Object-Oriented Perceptron API}{20}{section.2.6}%
\contentsline {section}{\numberline {2.7}Training of the Perceptron Algotithm on the Iris Dataset}{24}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}OvA method for multi-class classification}{24}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Training the Algorithm}{26}{subsection.2.7.2}%
\contentsline {section}{\numberline {2.8}Adaptive Linear Neurons and the Convergence of Learning}{30}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}Main Differenes Between Perceptron and Adaline}{30}{subsection.2.8.1}%
\contentsline {subsection}{\numberline {2.8.2}Minimizing Loss Function with Gradient Descent}{30}{subsection.2.8.2}%
\contentsline {section}{\numberline {2.9}Implementing Adaline in Python}{33}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}Hyperparameters}{36}{subsection.2.9.1}%
\contentsline {section}{\numberline {2.10}Improving Gradient Descent Through Feature Scaling}{36}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}Large-Scale Machine Learning and Stochastic Gradient Descent}{38}{subsection.2.10.1}%
\contentsline {chapter}{\numberline {3}A Tour of Machine Learning Classifiers Using Scikit-Learn}{43}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{43}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Choosing a Classification Algorithm}{43}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}First Steps with scikit-learn Training a Perceptron}{44}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}Training a Model Using Scikit-Learn}{44}{subsection.3.1.3}%
\contentsline {section}{\numberline {3.2}Modeling Class Probabilities Via Logistic Regression}{49}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Logistic Regression and Conditional Probabilities}{49}{subsection.3.2.1}%
\contentsline {section}{\numberline {3.3}Learning the Model Weights via the Logistic Loss Function}{52}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Deriving the likelihood function}{52}{subsection.3.3.1}%
\contentsline {section}{\numberline {3.4}Converting an Adaline Implementation Into an Algorithm for Logistic Regression}{53}{section.3.4}%
\contentsline {section}{\numberline {3.5}Gradient Descent}{56}{section.3.5}%
\contentsline {section}{\numberline {3.6}Training a Logistic Regression Model with Scikit-Learn}{56}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Algorithms for convex optimization}{58}{subsection.3.6.1}%
\contentsline {section}{\numberline {3.7}Tackling Overfitting via Regularization}{60}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}The Bias-Variance Tradeoff}{61}{subsection.3.7.1}%
\contentsline {chapter}{\numberline {A}Using Python for Machine Learning}{63}{appendix.A}%
\contentsline {section}{\numberline {A.1}Basic Configuration}{63}{section.A.1}%
\contentsline {section}{\numberline {A.2}Anaconda Python Distribution and Package Manager}{64}{section.A.2}%
\contentsline {section}{\numberline {A.3}Packages for Scientific Computing, Data Science, and Machine Learning}{64}{section.A.3}%
\contentsline {chapter}{\numberline {B}A Note on Distributions}{66}{appendix.B}%
\contentsline {section}{\numberline {B.1}Normal Distrubution}{66}{section.B.1}%
\contentsline {section}{\numberline {B.2}Bernoulli's Distribution}{66}{section.B.2}%
