\documentclass[../../introduccion.tex]{subfiles}

\begin{document}

    \setcounter{chapter}{2}

    \chapter{Introducción}
    
    \section{Fundamentos}

    El objetivo principal de la teoría de las funciones analíticas es el análisis de funciones que localmente pueden ser descritas en términos de una serie de potencias convergente, dispuesta como:
    \begin{equation}
        \begin{split}
            f(x)&=a_0+a_1(x-x_0)+a_2(x-x_0)^2+...+a_n(x-x_0)^n+...\\
            &=\sum_{ k=0}^\infty a_k(x-x_0)^k,\quad\forall x\in]x_0-\delta,x_0+\delta[
        \end{split}
    \end{equation}
    siendo $\cf{f}{I}{\mathbb{R}}$ con $I$ un intervalo, $x_0\in I$ y $\delta>0$ tal que $]x_0-\delta,x_0+\delta[\subseteq]a,b[$. Cuando una funcion de este tipo puede ser descrita de la forma anterior para algún par $x_0$ y $\delta$, decimos en este caso que \tbf{$f$ es analítica en $x_0$}.

    En el caso que $I$ sea un intervalo abierto y $f$ sea analítica en $x_0$ para todo $x_0\in I$, decimos que \tbf{$f$ es analítica en $I$}.

    \begin{exa}
        Las funciones $x\mapsto P(x)$, $x\mapsto e^x$, $x\mapsto \sin x$ y $x\mapsto \cos x$ son analíticas en $\mathbb{R}$
    \end{exa}

    Debido a que como resultado de efectuar operaciones algebraicas y analíticas (suma, resta, multiplicación, división, integración y derivación) sobre series de potencias resulta nuevamente en una serie de potencias convergente, es de gran interés conocer las propiedades de estas funciones (más que nada debido a las ecuaciones diferenciales). Esto motiva el estudio particular de este tipo  de funciones.

    A pesar de lo amplia que es esta clase de funciones, ésta solamente forma una parte regular de las funciones \textit{infinitamente diferenciables}.

    \begin{propo}
        Sea $\cf{f}{]x_0-r,x_0+r[}{\mathbb{R}}$ una función, siendo $r>0$ y $x_0\in\mathbb{R}$. Entonces, $f$ es analítica en $x_0$ si y sólo si se satisfacen las condiciones siguientes:
        \begin{enumerate}
            \item $f$ tiene derivadas de todos los órdenes en un entorno de $x_0$.
            \item Existen $\delta,M>0$ tales que para todo $x\in]x_0-\delta,x_0+\delta[$ y para todo $k\in\mathbb{N}$ se cumple:
            \begin{equation*}
                \abs{f^{(k)}(x)}<M\frac{k!}{\delta^k}
            \end{equation*}
        \end{enumerate}
    \end{propo}

    \begin{proof}
        $\Rightarrow):$ Suponga que $f$ es analítica en $x_0$, entonces existen $a_0,a_1,...,a_n,...\in\mathbb{R}$ y $\rho>0$ tal que
        \begin{equation*}
            f(x)=a_0+a_1(x-x_0)+a_2(x-x_0)^2+...
        \end{equation*}
        para todo $x\in]x_0-\rho,x_0+\rho[$ (note que $\rho<r$). Se sabe por resultados de análisis real que $f$ tiene derivadas de todos los órdenes en $]x_0-\rho,x_0+\rho[$ y, en particular para todo $k\in\mathbb{N}$ se tiene que
        \begin{equation*}
            f^{(k)}(x)=k!a_k+\frac{(k+1)!}{1!}a_{ k+1}(x-x_0)+\frac{(k+2)!}{2!}a_{ k+2}(x-x_0)^2+...+\frac{(k+n)!}{n!}a_{ k+n}(x-x_0)^n+...
        \end{equation*}
        para todo $x\in]x_0-\rho,x_0+\rho[$. Fijemos $k\in\mathbb{N}$ y tomemos $\delta>0$ tal que $0<2\delta<\rho$. Si $x=x_0+2\delta$, entonces la serie anterior convergerá y, por ende en el límite debe suceder que
        \begin{equation*}
            \begin{split}
                \lim_{ n\rightarrow\infty}\frac{(k+n)!}{n!}a_{ k+n}(x-x_0)^n&=0\\
                \iff \lim_{ n\rightarrow\infty}a_{ k+n}(x_0+2\delta-x_0)^n&=0\\
                \iff a^k\lim_{ n\rightarrow\infty}a_{n}(2\delta)^n&=0\\
                \iff \lim_{ n\rightarrow\infty}a_{n}(2\delta)^n&=0\\
            \end{split}
        \end{equation*}
        (pues, $\lim_{ n\rightarrow\infty}\frac{(k+n)!}{n!}=1$). En particular, de lo anterior se deduce que $\left\{a_n(2\delta)^n \right\}_{ n=1}^{\infty}$ es una sucesión acotada, luego existe $M>0$ tal que
        \begin{equation*}
            \abs{a_n(2\delta)^n}<M',\quad\forall n\in\mathbb{N}
        \end{equation*}
        Por tanto, se tiene que para todo $x\in]x_0-\delta,x_0+\delta[$, al ser la serie de potencias convergente y ser el espacio $(\mathbb{R},\abs{\cdot})$ completo, es absolutamente convergente, luego:
        \begin{equation*}
            \begin{split}
                \abs{f^{(k)}(x)}&\leq k!\abs{a_k}+\frac{(k+1)!}{1!}\abs{a_{ k+1}}\abs{x-x_0}+...+\frac{(k+n)!}{n!}\abs{a_{ k+n}}\abs{x-x_0}^n+...\\
                &\leq k!\abs{a_k}+\frac{(k+1)!}{1!}\abs{a_{ k+1}}\abs{x_0+\delta-x_0}+...+\frac{(k+n)!}{n!}\abs{a_{ k+n}}\abs{x_0+\delta-x_0}^n+...\\
                &\leq k!\abs{a_k}+\frac{(k+1)!}{1!}\abs{a_{ k+1}}\delta+...+\frac{(k+n)!}{n!}\abs{a_{ k+n}}\delta^n+...\\
                &< k!\frac{M'}{(2\delta)^k}+\frac{(k+1)!}{1!}\cdot\frac{M'}{(2\delta)^{ k+1}}\delta+...+\frac{(k+n)!}{n!}\cdot\frac{M'}{(2\delta)^{ k+n}}\delta^n+...\\
                &=\frac{k!M'}{2^k}\left[1+\frac{k+1}{1!}\cdot\frac{1}{2}+...+\frac{(k+1)(k+2)\cdot...\cdot(k+n)}{n!}\cdot\frac{1}{2^n}+... \right]\\
            \end{split}
        \end{equation*}

    \end{proof}

    \chapter{Propiedades Elementales y Ejemplos de Funciones Analíticas}
    
    \section{Series de Potencias}

    Se darán ejemplos y se hablará sobre las propiedades fundamentales de las series de potencias.

    \begin{mydef}
        Sea $\left\{ a_n \right\}_{ n=1}^\infty$ una sucesión en $\mathbb{C}$. Decimos que la serie de $\sum_{n=1}^\infty a_n$ \tbf{converge a $z\in\mathbb{C}$}, si para todo $\varepsilon>0$ existe $N\in\mathbb{N}$ tal que
        \begin{equation*}
            n\geq N\Rightarrow\abs{\sum_{ k=1}^na_n-z }<\varepsilon
        \end{equation*}
        La serie $\sum_{n=1}^\infty a_n$ \tbf{converge absolutamente}, si $\sum_{n=1}^\infty\abs{a_n}$ converge.
    \end{mydef}

    \begin{propo}
        Si $\sum_{n=1}^\infty a_n$ converge absolutamente, entonces $\sum_{n=1}^\infty a_n$ es convergente.
    \end{propo}

    \begin{proof}
        Inmediata de las propiedades del módulo.
    \end{proof}

    \begin{mydef}
        Sea $\left\{a_n \right\}_{ n=1}^\infty$ una sucesión en $\mathbb{R}$. Se definen:
        \begin{itemize}
            \item $\limsup_{ n\rightarrow\infty}a_n=\lim_{ n\rightarrow\infty}\sup\left\{a_n,a_{ n+1},... \right\}$.
            \item $\liminf_{ n\rightarrow\infty}a_n=\lim_{ n\rightarrow\infty}\inf\left\{a_n,a_{ n+1},... \right\}$.
        \end{itemize}
        como el número real en $\overline{\mathbb{R}}$.
    \end{mydef}

    \begin{obs}
        El límite superior y límite inferior de una sucesión siempre existe.
    \end{obs}

    \begin{mydef}
        Una \tbf{serie de potencias alrededor de $a\in\mathbb{C}$} es una serie de la forma $\sum_{ n=0}^\infty a_n(z-a)^n$, siendo $\left\{ a_n \right\}_{ n=1}^\infty$ una sucesión en $\mathbb{C}$ y $z\in\mathbb{C}$.
    \end{mydef}

    \begin{exa}
        La serie geométrica
        \begin{equation*}
            \sum_{ n=0}^\infty z^n
        \end{equation*}
        es convergente a $\frac{1}{1-z}$ si y sólo si $\abs{z}<1$.
    \end{exa}

    \begin{theor}[\tbf{Critero $M$ de Weierestrass}]
        Para cada $n\in\mathbb{N}$, sea $\cf{u_n}{X}{\mathbb{C}}$ una función tal que existe $M_n\in\mathbb{R}$ tal que
        \begin{equation*}
            \abs{u_n}(x)<M_n,\quad\forall x\in X
        \end{equation*}
        entonces, si $\sum_{ n=1}^\infty M_n<\infty$ se tiene que la serie
        \begin{equation*}
            \sum_{ n=1}^\infty u_n
        \end{equation*}
        converge uniformemente.
    \end{theor}

    \begin{proof}
        Se hizo en Análisis Matemático I.
    \end{proof}

    \begin{theor}
        Sea $\sum_{ n=0}^\infty a_n(z-a)^n$ una serie de potencias, defina el número $R\in[0,\infty]$ tal que
        \begin{equation*}
            \frac{1}{R}=\limsup_{ n\rightarrow\infty}\abs{a_n}^{ 1/n}
        \end{equation*}
        entonces:
        \begin{enumerate}
            \item Si $z\in\mathbb{C}$ es tal que $\abs{z-a}<R$, la serie converge absolutamente.
            \item Si $z\in\mathbb{C}$ es tal que $\abs{z-a}>R$, los términos de la serie no son acotados, por lo que la serie diverge.
            \item Si $0<r<R$, la serie converge uniformemente en $\left\{ z\in\mathbb{C}\Big|\abs{z}\leq r \right\}$.
        \end{enumerate}
        El elemento no negativo de la recta real extendida $R$ es el único con las propiedades (1) y (2), y es llamado el \tbf{radio de convergencia de la serie $\sum_{ n=0}^\infty a_n(z-a)^n$}.
    \end{theor}

    \begin{proof}
        De (1): Se tienen dos casos; si $R>0$ y $R=0$:
        \begin{itemize}
            \item \tbf{$R>0$}: Podemos suponer que $a=0$. Sea $z\in\mathbb{C}$ tal que $\abs{z}<R$. Existe $r\in\mathbb{R}$ tal que $\abs{z}<r<R$. $\frac{1}{R}=\limsup_{ n\rightarrow\infty}\abs{a_n}^{ 1/n}$, entonces existe $N\in\mathbb{N}$ tal que
            \begin{equation*}
                \abs{a_n}^{ 1/n}<\frac{1}{r},\quad\forall n\geq N
            \end{equation*}
            pues, $1/R<1/r$. Entonces:
            \begin{equation*}
                \abs{a_n}<\frac{1}{r^n},\quad\forall n\geq N
            \end{equation*}
            se sigue así que:
            \begin{equation*}
                \abs{a_nz^n}\leq\left(\frac{\abs{z}}{r}\right)^n,\quad\forall n\geq N
            \end{equation*}
            Por ende:
            \begin{equation*}
                \sum_{ n=N}^\infty\abs{a_nz^n}\leq\sum_{ n=N}^\infty\left(\frac{\abs{z}}{r}\right)^n<\infty
            \end{equation*}
            pues $\abs{z}/r<1$. Por tanto, la serie de potencias
            \begin{equation*}
                \sum_{ n=1}^\infty a_nz^n
            \end{equation*}
            es absolutamente convergente.
            \item Si $R=0$, entonces no existe $z\in\mathbb{C}$ tal que $\abs{z}<R$. Por tanto, el resultado se cumple por vacuidad.
        \end{itemize}

        De (2): El procedimiento es análogo (pero mostrando la divergencia de una serie geométrica) al de (1).

        De (3): Sea $r\in\mathbb{R}$ tal que $0<r<R$. Tomemos $\rho\in\mathbb{R}$ tal que $r<\rho<R$. Como en (1) existe $N\in\mathbb{N}$ tal que
        \begin{equation*}
            \abs{a_n}<\frac{1}{\rho},\quad\forall n\geq N
        \end{equation*}
        Entonces, si $\abs{z}\leq r$ se tiene que
        \begin{equation*}
            \abs{a_nz^n}\leq\left(\frac{r}{\rho}\right)^n,\quad\forall n\geq N
        \end{equation*}
        siendo $r/\rho<1$. Por el Criterio $M$ de Weierestrass se sigue que la serie de potencias
        \begin{equation*}
            \sum_{ n=1}^\infty \abs{a_nz^n}
        \end{equation*}
        converge uniformemente en $\left\{ z\in\mathbb{C}\Big|\abs{z}\leq r \right\}$.

        La unicidad de $R$ se sigue de (1) y (2).
    \end{proof}

    \begin{propo}
        Si $\sum_{ n=1}^\infty a_n(z-a)^n$ es una serie de potencias con radio de convergencia $R\in[0,\infty]$, entonces
        \begin{equation*}
            R=\lim_{n\rightarrow\infty}\abs{\frac{a_n}{a_{ n+1}}}
        \end{equation*}
        si el límite existe.
    \end{propo}

    \begin{proof}
        Poedmos suponer que $a=0$. Si el límite anterior existe, denotémoslo por
        \begin{equation*}
            \alpha=\lim_{n\rightarrow\infty}\abs{\frac{a_n}{a_{ n+1}}}
        \end{equation*}
        Probaremos que $\alpha=R$. Sea $z\in\mathbb{C}$:
        \begin{itemize}
            \item Suponga que $r\in\mathbb{R}$ es tal que $\abs{z}<r<\alpha$. Existe $N\in\mathbb{N}$ tal que
            \begin{equation*}
                \abs{\frac{a_{ n}}{a_{ n+1}}}>r,\quad\forall n\geq N
            \end{equation*}
            (pues, el límite converge a $\alpha$). Sea $B=\abs{a_n}r^N$. Entonces:
            \begin{equation*}
                \begin{split}
                    \abs{a_{ N+1}}r^{N+1}&=\abs{a_{ N+1}}rr^{N}\\
                    &<\abs{a_N}r^N\\
                    &=B\\
                \end{split}
            \end{equation*}
            por inducción se prueba rápidamente que:
            \begin{equation*}
                \abs{a_nr^n}\leq B,\quad\forall n\geq N
            \end{equation*}
            Entonces:
            \begin{equation*}
                \begin{split}
                    \abs{a_nz^n}&=\abs{a_nr^n}\cdot\frac{\abs{z^n}}{r^n}\\
                    &=B\cdot\frac{\abs{z}^n}{r^n},\quad\forall n\geq N \\
                \end{split}
            \end{equation*}
            Como $\abs{z}<r$, entonces $\frac{\abs{z}}{r}<1$. Por lo cual la serie
            \begin{equation*}
                \sum_{ n=1}^\infty a_nz^n
            \end{equation*}
            es absolutamente convergente para todo $z\in\mathbb{C}$ tal que $\abs{z}<\alpha$. Por (1) del Teorema anterior, debe suceder que $\alpha\leq R$.
            \item Un procedimiento análogo al anterior pero con $\abs{z}>\alpha$ prueba que la serie
            \begin{equation*}
                \sum_{ n=1}^\infty a_nz^n
            \end{equation*}
            no converge para todo $z\in\mathbb{C}$ tal que $\alpha<\abs{z}$. Por ende, $R\leq \alpha$
        \end{itemize}
        Por los dos incisos anteriores se sigue que $\alpha=R$.
    \end{proof}

    \begin{exa}
        La serie de potencias
        \begin{equation*}
            \sum_{ n=1}^\infty\frac{z^n}{n!}
        \end{equation*}
        tiene radio de convergencia $R=\infty$.
    \end{exa}

    \begin{proof}
        En efecto, veamos que:
        \begin{equation*}
            \begin{split}
                \lim_{n\rightarrow\infty}\abs{\frac{a_{ n}}{a_{n+1}}}&=\lim_{n\rightarrow\infty}\frac{(n+1)!}{n!}\\
                &=\lim_{n\rightarrow\infty}(n+1)\\
                &=\infty\\
            \end{split}
        \end{equation*}
        por lo cual, $R=\infty$.
    \end{proof}

    \begin{mydef}
        Se define la \tbf{función exponencial}, como la función $\cf{\exp}{\mathbb{C}}{\mathbb{C}}$ dada por:
        \begin{equation*}
            z\mapsto e^z=\exp(z)=\sum_{ n=0}^\infty\frac{z^n}{n!}
        \end{equation*}
        por la parte anterior, esta serie es absolutamente convergente en $\mathbb{C}$, por lo que la función $\exp$ está bien definida.
    \end{mydef}

    \begin{propo}
        \label{MultSumSeriesPot}
        Sean $\sum_{n=0}^\infty a_n$ y $\sum_{n=0}^\infty b_n$ dos series absolutamente convergentes, y sea
        \begin{equation*}
            c_n=\sum_{ k=0}^n b_ka_{ n-k},\quad\forall n\in\mathbb{N}\cup\left\{0\right\}
        \end{equation*}
        entonces, $\sum_{n=0}^\infty c_n$ es absolutamente convergente, y:
        \begin{equation*}
            \sum_{n=0}^\infty c_n=\left(\sum_{n=0}^\infty a_n\right)\cdot\left(\sum_{n=0}^\infty b_n\right)
        \end{equation*}
    \end{propo}

    \begin{proof}
        %TODO
        Ejercicio.
    \end{proof}

    \section{Funciones Analíticas}

    Se definen las funciones analíticas y se dan algunos ejemplos.

    \begin{mydef}
        Sea $G\subseteq\mathbb{C}$ abierto y $\cf{f}{G}{\mathbb{C}}$ una función. Entonces, $f$ es \tbf{diferenciable en $a\in G$}, si el límite:
        \begin{equation*}
            \lim_{ h\rightarrow0}\frac{f(a+h)-f(a)}{h}
        \end{equation*}
        existe; el valor de este límite es denotado por $f'(a)$ y es llamado la \tbf{derivada de $f$ en $a$}. Si $f$ es diferenciable en todo punto de $G$, decimos que $f$ es \tbf{diferenciable en $G$}.

        Si $f'$ es continua, decimos que $f$ es \tbf{diferenciable continua}. Si $f'$ es diferenciable, decimos que $f$ es \tbf{dos veces diferenciable}, continuando, una función $f$ tal que cada derivada sucesiva es diferenciable se dice \tbf{infinitamente diferenciable}.
    \end{mydef}

    \begin{obs}
        Puede entonces definirse una función $\cf{f'}{G'\subseteq G}{\mathbb{C}}$, donde $G'\subseteq G$ es el conjunto de puntos donde $f$ es diferenciable. En caso de que $f$ sea diferenciable en todo $G$, se sigue que $G'=G$.
    \end{obs}

    \begin{propo}
        Si una función $\cf{f}{G}{\mathbb{C}}$ es diferenciable en $a\in G$, entonces $f$ es continua en $a$.
    \end{propo}

    \begin{proof}
        Veamos que:
        \begin{equation*}
            \begin{split}
                \lim_{ z\rightarrow a}\abs{f(z)-f(a)}&=\lim_{ z\rightarrow a}\left(\frac{\abs{f(z)-f(a)}}{\abs{z-a}}\cdot\abs{z-a}\right)\\
                &=\lim_{ z\rightarrow a}\left(\frac{\abs{f(z)-f(a)}}{\abs{z-a}}\right)\cdot\lim_{ z\rightarrow a}\abs{z-a}\\
                &=\abs{\lim_{ z\rightarrow a}\frac{f(z)-f(a)}{z-a}}\cdot 0\\
                &=\abs{f'(a)}\cdot 0\\
                &=0\\
            \end{split}
        \end{equation*}
        lo cual prueba el resultado.
    \end{proof}

    \begin{mydef}
        Una función $\cf{f}{G}{\mathbb{C}}$ es \tbf{analítica} si es diferenciable continua en $G$.
    \end{mydef}

    Se sigue rápidamente (como en cálculo), que las sumas y productos de funciones analíticas siguen siendo analíticas. Si $f$ y $g$ son analíticas en $G$ y $G_1$ es el conjunto de puntos donde $g$ no es cero, entonces $f/g$ es analítica en $G_1$.

    Como la función constante y $z$ son analíticas, se sigue que todas las funciones racionales son analíticas en el complemento de los ceros del denominador.

    Más aún, todas las leyes de diferenciación de sumas, productos y cocientes siguen siendo válidas.

    \begin{theor}[\tbf{Regla de la Cadena}]
        Sean $f,g$ funciones analíticas en $G$ y $\Omega$, respectivamente y suponga que $f(G)\subseteq\Omega$. Entonces, $f\circ g$ es analítica en $G$ y:
        \begin{equation*}
            (g\circ f)'(z)=g'(f(z))\cdot f'(z),\quad\forall z\in G
        \end{equation*}
    \end{theor}

    \begin{proof}
        Sea $z_0\in G$. Como $G$ es abierto, existe $r>0$ tal que
        \begin{equation*}
            \left\{\abs{z_0-z}<r\Big|z\in\mathbb{C} \right\}\subseteq G
        \end{equation*}
        para probar que el límite
        \begin{equation*}
            \lim_{ h\rightarrow 0}\frac{g\circ f(z_0+h)-g\circ f(z_0)}{h}
        \end{equation*}
        existe, basta con mostrar que para toda sucesión $\left\{h_n \right\}_{ n=1}^\infty$ en $\mathbb{C}\setminus\left\{0\right\}$ que converja a 0 se cumple que el límite
        \begin{equation*}
            \lim_{ n\rightarrow\infty}\frac{g\circ f(z_0+h_n)-g\circ f(z_0)}{h_n}
        \end{equation*}
        existe y es igual a $g'(f(z_0))\cdot f'(z_0)$. En efecto, sea $\left\{h_n \right\}_{ n=1}^\infty$ una sucesión que converge a 0, podemos asumir que:
        \begin{equation*}
            0<\abs{h_n}<r,\quad\forall n\in\mathbb{N}
        \end{equation*}
        Haremos la prueba por casos:
        \begin{enumerate}[label = \textit{\quad Caso \arabic*:}]
            \item Suponga que $f(z_0)\neq f(z_0+h_n)$ para todo $n\in\mathbb{N}$. En este caso:
            \begin{equation*}
                \begin{split}
                    \frac{g\circ f(z_0+h_n)-g\circ f(z_0)}{h_n}&=\frac{g\circ f(z_0+h_n)-g\circ f(z_0)}{f(z_0+h_n)-f(z_0)}\cdot\frac{f(z_0+h_n)-f(z_0)}{h_n}\\
                \end{split}
            \end{equation*}
            por ser $f$ continua, se sigue que:
            \begin{equation*}
                \lim_{ n\rightarrow\infty}f(z_0+h_n)-f(z_0)=0
            \end{equation*}
            por lo que, al tomar límite cuando $n\rightarrow\infty$ se obtiene que:
            \begin{equation*}
                \lim_{ n\rightarrow\infty}\frac{g\circ f(z_0+h_n)-g\circ f(z_0)}{h_n}=g'(f(z_0))\cdot f'(z_0)
            \end{equation*}
            \item $f(z_0)=f(z_0+h_n)$ para todo $n\in J\subseteq\mathbb{N}$, donde $J$ es un conjunto infinito.%TODO
        \end{enumerate}
    \end{proof}

    \begin{mydef}
        Una función compleja $f$ se dirá \tbf{analítica en $A\subseteq\mathbb{C}$}, si existe $G\subseteq\mathbb{C}$ abierto tal que $f$ es analítica en $G$ y $A\subseteq G$.
    \end{mydef}

    En lo que sigue de este curso, se hará el mayor esfuerzo para ver porqué la teoría de las funciones analíticas es \textit{extremandamente} diferente del cálculo tradicional.

    \begin{propo}
        Sea $f(z)=\sum_{ n=0}^\infty a_n(z-a)^n$ una serie de potencias con radio de convergencia $R>0$. Entonces:
        \begin{enumerate}[label = \textit{(\arabic*)}]
            \item Para cada $k\geq 1$, la serie:
            \begin{equation}
                \label{derivadaSeriePotencias}
                \sum_{n=k}^\infty n(n-1)\cdots(n-k+1)a_n(z-a)^{ n-k}
            \end{equation}
            tiene radio de convergencia $R>0$.
            \item La función $f$ es infinitamente diferenciable en $B(a,R)$ y más aún, $f^{(k)}$ está dada por la serie en la ecuación (\ref{derivadaSeriePotencias}).
            \item Para todo $n\geq0$:
            \begin{equation*}
                a_n=\frac{1}{n!}f^{(n)}(a)
            \end{equation*}
        \end{enumerate}
    \end{propo}

    \begin{proof}
        Podemos asumir que $a=0$, ya que la función $z\mapsto z-a$ es diferenciable en $\mathbb{C}$ y composición de funciones diferenciables es diferenciable.

        De \textit{(a)}: Basta probar el caso con $k=1$, ya que por inducción se sigue rápidamente que se cumple para todo $k\geq1$. Probaremos que el radio de convergencia de la serie:
        \begin{equation*}
            \sum_{ n=1}^\infty na_nz^{ n-1}
        \end{equation*}
        es $R$. Para ello, recordemos que como $\sum_{ n=0}^\infty a_n(z-a)^n$ tiene radio de convergencia $R$, se tiene:
        \begin{equation*}
            \frac{1}{R}=\limsup_{ n\rightarrow\infty}\abs{a_n}^{ 1/n}
        \end{equation*}
        queremos probar que:
        \begin{equation*}
            \frac{1}{R}=\limsup_{ n\rightarrow\infty}\abs{na_n}^{ 1/{n-1}}
        \end{equation*}
        veamos que el límite $\lim_{n\rightarrow\infty}n^{\frac{1}{n-1}}$ existe, pues se tiene que:
        \begin{equation*}
            \begin{split}
                \lim_{ n\rightarrow\infty}\frac{\ln n}{n-1}&=\lim_{ n\rightarrow\infty}\frac{1}{n}\\
                &=0\\
                \Rightarrow\lim_{ n\rightarrow\infty}\ln\left(n^{\frac{1}{n-1}} \right)&=0\\
            \end{split}
        \end{equation*}
        al ser $x\mapsto \ln x$ una función continua, se sigue que:
        \begin{equation*}
            \lim_{ n\rightarrow\infty}n^{\frac{1}{n-1}}=1
        \end{equation*}
        Del Ejercicio (\ref{productoSucesionesLimSupLim}) se sigue que:
        \begin{equation*}
            \begin{split}
                \limsup_{ n\rightarrow\infty}\abs{na_n}^{\frac{1}{n-1}}&=1\cdot\limsup_{ n\rightarrow\infty}\abs{a_n}^{\frac{1}{n-1}}\\
                &=\limsup_{ n\rightarrow\infty}\abs{a_n}^{\frac{1}{n-1}}\\
            \end{split}
        \end{equation*}
        veamos que el límite superior anterior es $\frac{1}{R}$. Sea $R'>0$ tal que:
        \begin{equation*}
            \frac{1}{R'}=\limsup_{ n\rightarrow\infty}\abs{a_n}^{\frac{1}{n-1}}\\
        \end{equation*}
        Entonces, $R'$ es el radio de convergencia de la serie:
        \begin{equation*}
            \sum_{ n=1}^\infty a_nz^{ n-1}=\sum_{ n=0}^\infty a_{n+1}z^{n}
        \end{equation*}
        Observemos ahora que:
        \begin{equation*}
            \sum_{ n=0}^\infty a_nz^n=z\sum_{ n=0}^\infty a_{ n+1}z^n+a_0
        \end{equation*}
        Por lo que la sere de la derecha converge si y sólo si la de la izquierda lo hace, es decir:
        \begin{equation*}
            \abs{z}<R'\iff \abs{z}<R'
        \end{equation*}
        Por ende, $R=R'$.

        De \textit{(b)}: Nuevamente, solo hay que probar que la función es diferenciable. Sea:
        \begin{equation*}
            g(z)=\sum_{ n=1}^\infty na_nz^{ n-1}
        \end{equation*}
        Esta serie tiene radio de convergencia $R>0$. Tomemos:
        \begin{equation*}
            s_n(z)=\sum_{ k=0}^n a_kz^k\quad\textup{y}\quad R_n(z)=\sum_{ k=n+1}^\infty a_kz^k
        \end{equation*}
        Sea $0<r<R$, $\varepsilon>0$ y tomemos $w\in\bbm{C}$ tal que $\abs{w}<r$. Probaremos que $f'(w)$ existe y es igual a $g(w)$. En efecto, tomemos $\delta>0$ tal que:
        \begin{equation*}
            \overline{B(w,\delta)}\subseteq B(w,r)
        \end{equation*}
        Sea $z\in B(w,\delta)$, entonces:
        \begin{equation*}
            \frac{f(z)-f(w)}{z-w}-g(w)=\left[\frac{s_n(z)-s_n(w)}{z-w}-s_n'(w) \right]+[s_n'(w)-g(w)]+\left[\frac{R_n(z)-R_n(w)}{z-w}\right] 
        \end{equation*}
        Ahora:
        \begin{equation*}
            \begin{split}
                \frac{R_n(z)-R_n(w)}{z-w}&=\frac{1}{z-w}\sum_{ k=n+1}^\infty a_k(z^k-w^k)\\
                &=\sum_{ k=n+1}^\infty a_k\left(\frac{z^k-w^k}{z-w} \right)\\
            \end{split}
        \end{equation*}
        con:
        \begin{equation*}
            \abs{\frac{z^k-w^k}{z-w}}=\abs{z^{k-1}+z^{k-2}w+\cdots+zw^{ k-2}+w^{ k-1} }\leq kr^{ k-1}
        \end{equation*}
        Por tanto:
        \begin{equation*}
            \abs{\frac{R_n(z)-R_n(w)}{z-w}}\leq\sum_{ k=n+1}^\infty a_kkr^{ k-1}
        \end{equation*}
        Como $r<R$, entonces la serie anterior converge, así que existe $N_1\in\bbm{N}$ tal que:
        \begin{equation*}
            n\geq N_1\Rightarrow \abs{\frac{R_n(z)-R_n(w)}{z-w}}<\frac{\varepsilon}{3}
        \end{equation*}
        Adicionalmente, como $\lim_{ n\rightarrow\infty }s_n'(w)=g(w)$, existe $N_2\in\bbm{N}$ tal que:
        \begin{equation*}
            n\geq N_2\Rightarrow \abs{s_n'(w)-g(w)}<\frac{\varepsilon}{3}
        \end{equation*}
        Sea $N=\max\left\{N_1,N_2 \right\}$. Como $s_N$ es diferenciable con derivada $s_N'$, se tiene que existe $\delta>0$ tal que:
        \begin{equation*}
            0<\abs{z-w}<\delta\Rightarrow \abs{\frac{s_n(z)-s_n(w)}{z-w}-s_n'(w)}<\frac{\varepsilon}{3}
        \end{equation*}
        Por tanto, poniendo todas las desigualdades juntas resulta que:
        \begin{equation*}
            0<\abs{z-w}<\delta\Rightarrow\abs{\frac{f(z)-f(w)}{z-w}-g(w)}<\varepsilon
        \end{equation*}
        Por tanto, $f'(w)=g(w)$.

        De \textit{(c)}: Es inmediato de evaluar las derivadas en $z=a$.
    \end{proof}

    \begin{cor}
        Si la serie de potencias $\sum_{ n=0}^\infty a_n(z-a)^n$ tiene radio de convergencia $R>0$, entonces $f(z)=\sum_{ n=0}^\infty a_n(z-a)^n$ es analítica en $B(a,R)$.
    \end{cor}

    \begin{proof}
        Inmediata del teorema anterior.
    \end{proof}

    \begin{exa}
        Por el Teorema anterior se sigue de forma inmediata se sigue que la función:
        \begin{equation*}
            z\mapsto e^z=\sum_{ n=0}^\infty\frac{z^n}{n!}
        \end{equation*}
        es analítica en $\bbm{C}$.
    \end{exa}

    \begin{propo}
        Si $G\subseteq\bbm{C}$ es abierto y conexo, y la función $\cf{f}{G}{\bbm{C}}$ es diferenciable con $f'(z)=0$ para todo $z\in G$, entonces $f$ es constante.
    \end{propo}

    \begin{proof}
        Sea $z_0\in G$ y tomemos $\omega=f(z_0)$. Probaremos que el conjunto:
        \begin{equation*}
            A=\left\{z\in G\Big|f(z)=\omega \right\}
        \end{equation*}
        es abierto y cerrado no vacío, por ende es todo $G$. En efecto, sea $z\in\overline{A}\cap G$, entonces existe una sucesión $\left\{z_n \right\}_{ n=1}^\infty$ en $A$ tal que:
        \begin{equation*}
            \lim_{ n\rightarrow\infty}z_n=z
        \end{equation*}
        Como $f$ es diferenciable, en particular es continua, por lo que:
        \begin{equation*}
            \omega=\lim_{ n\rightarrow}f(z_n)=f(z)
        \end{equation*}
        Así que $z\in A$. Por tanto, $A=\overline{A}^G$, es decir que $A$ es cerrado en $G$.

        Ahora, sea $z\in A$, entonces existe $\varepsilon>0$ tal que $B(z,\varepsilon)\subseteq G$ y tomemos $w\in B(z,w)$. Definimos la función $\cf{g}{[0,1]}{\bbm{C}}$ dada por:
        \begin{equation*}
            g(t)=f(tz+(1-t)w),\quad\forall t\in[0,1]
        \end{equation*}
        Entonces, se tiene que $g$ es diferenciable en $[0,1]$ y:
        \begin{equation*}
            \begin{split}
                \frac{dg}{dt}(t)&=f'(tz+(1-t)w)\cdot \frac{d}{dt}(tz+(1-t)w)\\
                &=f'(tz+(1-t)w)\cdot(z-w)\\
                &=0\\
            \end{split}
        \end{equation*}
        por el Ejercicio (\ref{normalDerivadaComplejaDerivadaCompos}) y ya que $f'=0$ en $G$. Por tanto, $g'=0$, es decir que $g$ es constante, en particular:
        \begin{equation*}
            f(w)=g(0)=g(1)=f(z)=\omega
        \end{equation*}
        Con lo que $w\in A$. Así que $B(z,\varepsilon)\subseteq A$.
    \end{proof}

    \begin{mydef}
        Una función $f$ es \textbf{periódica con período $c\in\bbm{C}$} si $f(z+c)=f(z)$ para todo $z\in\bbm{C}$.
    \end{mydef}

    En particular, se tiene de algunos ejercicios que:
    \begin{equation*}
        e^z=e^{ z+c}\iff c=i\theta
    \end{equation*}
    con $\theta\in\bbm{R}$. Más aún, de las propiedades de la función seno y coseno se sigue que:
    \begin{equation*}
        \theta=2\pi ik,\quad\textup{ para algún }k\in\bbm{Z}
    \end{equation*}

    De esta forma se sigue que la función exponencial es periódica.

    Queremos ahora definir la función logarítmo, pero no lo podemos hacer con expansión en serie de potencias (ya que los limitaríamos a un disco) ni con la integral de $t\mapsto\frac{1}{t}$, para ello procederemos de la siguiente manera:

    Queremos una función tal que:
    \begin{equation*}
        w\mapsto\log w=z\iff w=e^z
    \end{equation*}

    Como $e^z$ nunca es cero, logaritmo no puede estar definido en cero. Por tanto, supongamos que $e^z=w$ y $w\neq 0$. Si $z=x+iy$, entonces $\abs{w}=e^x$ y $y=\arg w+2\pi k$ para alguna $k\in\bbm{Z}$ (por la periodicidad de $e^z$).
    
    Así que el conjunto:
    \begin{equation*}
        \left\{\ln\abs{w}+i(\arg w+2\pi k)\Big|k\in\bbm{Z} \right\}
    \end{equation*}
    es un conjunto solución de $e^z=w$ (siendo $\ln\abs{w}$ el logaritmo usual).

    \begin{mydef}[\textbf{Rama de logarítmo}]
        Si $G$ es un conjunto abierto de $\bbm{C}$ y $\cf{f}{G}{\bbm{C}}$ es continua tal que:
        \begin{equation*}
            z=e^{ f(z)},\quad\forall z\in G
        \end{equation*}
        decimos que $f$ es una \textbf{rama de logarítmo}.
    \end{mydef}

    \begin{obs}
        Si $f$ es una rama de logarítmo en el conjunto abierto conexo $G$, entonces $g(z)=f(z)+2\pi ik$ también lo es. ¿El converso se cumple?
    \end{obs}

    \begin{propo}[\textbf{Caracterización de las ramas de logarítmo}]
        Sea $G\subseteq\bbm{C}$ abierto y conexo, $f$ una rama de logarítmo en $G$. Entonces todas las ramas de logarítmo en $G$ son de la forma:
        \begin{equation*}
            f(z)+2\pi ik
        \end{equation*}
        para algún $k\in\bbm{Z}$.
    \end{propo}

    \begin{proof}
        %TODO
    \end{proof}

    %TODO

    \section{Ecuaciones de Cauchy-Riemann}

    Sea $\cf{f}{G}{\bbm{C}}$ una función analítica (con $G\subseteq\bbm{C}$ abierto) y consideremos las funciones $\cf{u,v}{G}{\bbm{R}}$ (en este caso viendo a $G$ como subconjunto de $\bbm{R}^2$) dadas por:
    \begin{equation*}
        u(x,y)=\Re f(x+iy)\quad\textup{y}\quad v(x,y)=\Im f(x+iy)
    \end{equation*}
    para todo $x+iy\in G$. Al ser $f$ analítica en $G$ se sigue que para todo $z\in G$ el siguiente límite existe:
    \begin{equation*}
        f'(z)=\lim_{ h\rightarrow0}\frac{f(z+h)-f(z)}{h}
    \end{equation*}
    Evaluemos el límite anterior de dos maneras distintas. Dado que el límite siempre existe, podemos tomar $h\rightarrow0$ de valores reales. En este caso tenemos que si $h\neq0$ y $h\in\bbm{R}$:
    \begin{equation*}
        \begin{split}
            \frac{f(z+h)-f(z)}{h}&=\frac{f(x+iy+h)-f(x+iy)}{h}\\
            &=\frac{u(x+h,y)-u(x,y)}{h}+i\frac{v(x+h,y)-v(x,y)}{h}\\
        \end{split}
    \end{equation*}
    con $z=x+iy$. Tomando límite cuando $h\rightarrow0$ obtenemos que:
    \begin{equation*}
        f'(x+iy)=\frac{\partial u}{\partial x}(x,y)+i\frac{\partial v}{\partial x}(x,y)
    \end{equation*}
    De manera análoga pero ahora siendo $h=ir$ con $r\in\bbm{R}$ no cero, obtenemos que:
    \begin{equation*}
        f'(x+iy)=-i\frac{\partial u}{\partial y}(x,y)+\frac{\partial v}{\partial y}(x,y)
    \end{equation*}
    Por lo que:
    \begin{equation*}
        \frac{\partial u}{\partial x}(x,y)+i\frac{\partial v}{\partial x}(x,y)=-i\frac{\partial u}{\partial y}(x,y)+\frac{\partial v}{\partial y}(x,y)
    \end{equation*}
    Igualando las partes real e imaginarias obtenemos las \textbf{ecuaciones de Cauchy-Riemann}:
    \begin{equation}
        \label{ecuacionesCauchyRiemann}
        \frac{\partial u}{\partial x}(x,y)=\frac{\partial v}{\partial y}(x,y)\quad\textup{y}\quad\frac{\partial v}{\partial x}(x,y)=-\frac{\partial u}{\partial y}(x,y)
    \end{equation}
    para todo $x+iy\in G$.

    \begin{obs}[\textbf{$u$ es Función Harmónica}]
        Si diferenciamos parcialmente dos veces respecto a la variable $x$ y respecto a la variable $y$, respectivamente, las ecuaciones en (\ref{ecuacionesCauchyRiemann}) obtenemos:
        \begin{equation*}
            \frac{\partial^2 u}{\partial^2 x}=\frac{\partial^2v}{\partial x\partial y}\quad\textup{y}\quad\frac{\partial^2 u}{\partial^2 y}=-\frac{\partial^2v}{\partial y\partial x}
        \end{equation*}
        (siempre que $u$ y $v$ tengan segundas derivadas parciales). Si son continuas, podemos intercambiar el orden de diferenciación parcial obtenemos sumando ambas ecuaciones que:
        \begin{equation}
            \label{uEsArmonicaCauchyRiemann}
            \frac{\partial^2 u}{\partial^2 x}+\frac{\partial^2 u}{\partial^2 y}=0
        \end{equation}
        Toda función $u$ que satisfaga la ecuación (\ref{uEsArmonicaCauchyRiemann}) es llamada \textbf{Harmónica}. Más adelante se estudiarán este tipo de funciones con detalle.
    \end{obs}

    Sea $G$ un abierto de $\bbm{C}$ y tomemos $\cf{u,v}{G}{\bbm{R}}$ funciones con derivadas parciales continuas (respecto a $x$ y $y$). Más aún, supongamos que $u$ y $v$ satisfacen las ecuaciones de Cauchy-Riemann. Si $\cf{f}{G}{\bbm{C}}$:
    \begin{equation*}
        f(z)=u(z)+iv(z),\quad\forall z\in G
    \end{equation*}
    entonces $f$ es analítica en $G$.

    \begin{proof}
        En efecto, sea $z=x+iy$ y tomemos $r>0$ tal que $B(z,r)\subseteq G$, para todo $h=s+it\in B(0,r)$ se cumple que:
        \begin{equation*}
            \begin{split}
                u(x+s,y+t)-u(x,y)&=\left[u(x+s,y+t)-u(x,y+t)\right]+\left[u(x,y+t)-u(x,y)\right]\\
            \end{split}
        \end{equation*}
        Por el Teorema del valor medio (respecto a $x$ y $y$), obtenemos que existen $s_1,t_1>0$ con $\abs{s_1}<\abs{s}$ y $\abs{t_1}<\abs{t}$ tales que:
        \begin{equation*}
            \left\{
                \begin{array}{rl}
                    u(x+s,y+t)-u(x,y+t)&=\frac{\partial u}{\partial x}(x+s_1,y+t)s\\
                    u(x,y+t)-u(x,y)&=\frac{\partial u}{\partial y}(x,y+t_1)t\\
                \end{array}
            \right.
        \end{equation*}
        Tomemos $\cf{\varphi}{G}{\bbm{R}}$ dada por:
        \begin{equation*}
            \varphi(s,t)=\left[u(x+s,y+t)-u(x,y)\right]-\left[\frac{\partial u}{\partial x}(x+s_1,y+t)s+\frac{\partial u}{\partial y}(x,y)t\right]
        \end{equation*}
        Por las dos igualdades anteriores se sigue que:
        \begin{equation*}
            \frac{\varphi(s,t)}{s+it}=\frac{s}{s+it}\left[u_x(x+s_1,y+t)-u_x(x,y)\right]+\frac{t}{s+it}\left[u_y(x,y+t_1)-u_y(x,y) \right]
        \end{equation*}
        Como $\varphi$ es continua (pues $u$, $u_x$ y $u_y$ lo son), al ser $\abs{s_1}<\abs{s}$ y $\abs{t_1}<\abs{t}$, si hacemos límite cuando $s+it\rightarrow0$, obtenemos que
        \begin{equation}
            \label{iff_cauchy_riemann_1}
            \lim_{s+it\rightarrow0}\frac{\varphi(s,t)}{s+it}=0
        \end{equation}
        En síntesis, tenemos que:
        \begin{equation}
            \label{iff_cauchy_riemann_2}
            u(x+s,y+t)-u(x,y)=\frac{\partial u}{\partial x}(x,y)s+\frac{\partial u}{\partial y}(x,y)t+\varphi(s,t)
        \end{equation}
        Similarmente, obtenemos que existe una función $\cf{\psi}{G}{\bbm{R}}$ tal que:
        \begin{equation}
            \label{iff_cauchy_riemann_3}
            \lim_{s+it\rightarrow0}\frac{\psi(s,t)}{s+it}=0
        \end{equation}
        y,
        \begin{equation}
            \label{iff_cauchy_riemann_4}
            v(x+s,y+t)-v(x,y)=\frac{\partial v}{\partial x}(x,y)s+\frac{\partial v}{\partial y}(x,y)t+\psi(s,t)
        \end{equation}
        Veamos que:
        \begin{equation*}
            \begin{split}
                \frac{f(z+s+it)-f(z)}{s+it}&=\frac{\left[u(x+s,y+t)+iv(x+s,y+t)\right]-\left[u(x,y)+iv(x,y)\right]}{s+it}\\
                &=\frac{\left[u(x+s,y+t)-u(x,y)\right]+i\left[v(x+s,y+t)-v(x,y)\right]}{s+it}\\
                &=\frac{\left[u_x(x,y)s+u_y(x,y)t+\varphi(s,t)\right]+i\left[v_x(x,y)s+v_y(x,y)t+\psi(s,t) \right]}{s+it}\\
            \end{split}
        \end{equation*}
        Dado que $u$ y $v$ satisfacen las ecuaciones de Cauchy-Riemann, se tiene que:
        \begin{equation*}
            u_x=v_y\quad\textup{y}\quad v_x=-u_y
        \end{equation*}
        por lo cual:
        \begin{equation*}
            \begin{split}
                \frac{f(z+s+it)-f(z)}{s+it}&=\frac{\left[u_x(x,y)s-v_x(x,y)t+\varphi(s,t)\right]+i\left[v_x(x,y)s+u_x(x,y)t+\psi(s,t) \right]}{s+it}\\
                &=\frac{u_x(x,y)(s+it)+v_x(x,y)(-t+is)}{s+it}+\frac{\varphi(s,t)+\psi(s,t)}{s+it}\\
                &=\frac{u_x(x,y)(s-it)+iv_x(x,y)(s+it)}{s+it}+\frac{\varphi(s,t)+\psi(s,t)}{s+it}\\
                &=u_x(x,y)+iv_x(x,y)+\frac{\varphi(s,t)+\psi(s,t)}{s+it}\\
            \end{split}
        \end{equation*}
        Por lo que:
        \begin{equation*}
            \frac{f(z+s+it)-f(z)}{s+it}=u_x(z)+iv_x(z)+\frac{\varphi(s,t)+\psi(s,t)}{s+it}
        \end{equation*}
        Por (\ref{iff_cauchy_riemann_1}) y (\ref{iff_cauchy_riemann_3}) se sigue que $f$ es diferenciable, más aún $f'(z)=u_x(x,y)+iv_x(x,y)$. Dado que $u_x$ y $v_x$ son continuas, se sigue que $f$ es analítica.
    \end{proof}

    \begin{obs}
        Aquí, $u_x$ denota a $\frac{\partial u}{\partial x}$, y lo análogo con los demás subíndices de $v$ y el restante de $u$.
    \end{obs}

    Lo anterior junto con las propiedades probadas al inicio de la sección prueban el siguiente teorema:

    \begin{theor}[\textbf{Caracterización de Funciones Analíticas}]
        Sean $u$ y $v$ funciones real valuadas con $(x,y)\mapsto u(x,y)$ y $(x,y)\mapsto v(x,y)$, definidas en un subconjunto de $\bbm{C}$ abierto tales que tienen derivadas parciales continuas. Entonces, la función $\cf{f}{G}{\bbm{C}}$ dada por:
        \begin{equation*}
            f(z)=u(z)+iv(z),\quad\forall z\in G
        \end{equation*}
        es analítica si y solo si $u$ y $v$ satisfacen las ecuaciones de Cauchy-Riemann, esto es que:
        \begin{equation*}
            u_x=v_y\quad\textup{y}\quad u_y=-v_x
        \end{equation*}
        Además:
        \begin{equation*}
            f'(z)=u_x(z)+iv_x(z)=v_y(z)-iu_y(z),\quad\forall z\in G
        \end{equation*}
    \end{theor}

    \begin{preg}
        Sean $G$ subconjunto de $\bbm{C}$ abierto y $\cf{u}{G}{\bbm{R}}$ una función armónica. ¿Existe una función armónica $v$ tal que $\cf{f}{G}{\bbm{C}}$ definida como:
        \begin{equation*}
            f(z)=u(z)+iv(z),\quad\forall z\in G
        \end{equation*}
        sea analítica?
    \end{preg}

    Esta pregunta se estudiará más adelante. Si tal función de la pregunta anterior existe, esta es llamada \textbf{conjugada armónica de $u$}. Si $v_1$ y $v_2$ son dos armónicas conjugadas de $u$, se puede probar que:
    \begin{equation*}
        i(v_1-v_2)=(u+iv_1)-(u+iv_2)
    \end{equation*}
    es una función analítica en $G$ que solo toma valores imaginarios.

    \begin{exa}
        La función $z\mapsto\log\abs{z}$ no tiene armónico conjungado en $\bbm{C}\setminus\left\{0\right\}$.
    \end{exa}

    De hecho, podemos caracterizar la existencia de conjugados armónicos en ciertas regiones de $\bbm{C}$:

    \begin{theor}
        Sea $G\subseteq\bbm{C}$ todo el plano o un disco abierto. Si $\cf{u}{G}{\bbm{R}}$ es armónica, entonces $u$ tiene conjugada armónica.
    \end{theor}

    \begin{proof}
        %TODO
    \end{proof}

    \section{Funciones Analíticas como Mapeos: Transformaciones de Möbius}

    Para empezar esta sección, consideremos la función $\cf{f}{G}{\bbm{C}}$ dada por $z\mapsto z^2$. Ya sabemos que esta función es analítica, pues se verifica rápidamente que cumplen las ecuaciones de Cauchy-Riemann.

    Si hacemos $f(z)=\mu+i\nu$, entonces tomando $z=x+iy$ obtenemos que:
    \begin{equation*}
        \mu(x,y)=x^2-y^2\quad\textup{y}\quad\nu(x,y)=2xy
    \end{equation*}
    Por tanto, las hipérbolas $c(x,y)=x^2-y^2$ y $d=2xy$ son mapeadas bajo $f$ a líneas rectas dadas por $\mu=c$ y $\nu=d$.

    \begin{obs}
        Si $c$ y $d$ no son cero, entonces las hipérbolas intersectan en ángulos rectos, tal y como lo hacen sus imágenes.
    \end{obs}

    La observación anterior se verá más adelante como un resultado general de cierto tipo de funciones.

    \begin{exa}
        Consideremos ahora las rectas $x=c$ y $y=d$. Si tomamos primeramente la recta $x=c$ (con $y$ arbitrario), entonces $f$ mapea esta línea a $\mu=c^2-y^2$ y $\nu=2cy$.

        Sustituyendo a $y$ en ambas ecuaciones observamos que $x=c$ es mapeado a la parábola $\nu^2=-4c^2(\mu-c^2)$.

        Similarmente, $f$ toma a la recta $y=d$ a la parábola $\nu^2=4d^2(\mu+d^2)$.

        Resulta que estas dos parábolas intersectan en el punto $(c^2-d^2,\pm\abs{cd})$ e intersectan en ángulo recto.
    \end{exa}

    \begin{exa}
        Consideremos la misma función $f$ y tomemos ahora la circunferencia $\vartheta\mapsto re^{i\vartheta}=z$, entonces $f(z)=r^2e^{ 2i\vartheta}$, esto es un círculo de radio $r^2$ que se recorre dos veces por cada recorrido que hacemos al círculo original.
    \end{exa}

    Justamente estos ejemplos nos brindan propiedades de la función $f$ que podremos generalizar a ciertas funciones analíticas.

    \begin{obs}
        Uno de los problemas principales en teoría de funciones analíticas es el siguiente: dados dos conjuntos abiertos y conexos, $G$ y $\Omega$, ¿existe una función analítica $f$ tal que $f[G]=\Omega$?
    \end{obs}

    La solución a este problema resultará útil más adelante.

    \subsection{Caminos}

    \begin{mydef}[\textbf{Camino}]
        Un camino en una región $G\subseteq\bbm{C}$ es una función $\cf{\gamma}{[a,b]}{G}$, siendo $[a,b]\subseteq\bbm{R}$.
        \begin{itemize}
            \item Decimos que $\gamma$ es \textbf{suave a piezas} o \textbf{por partes} si existe una partición del intervalo $[a,b]$, digamos $a=\gamma_0<\gamma_1<\dots<t_n=b$ tal que $\gamma$ es suave en cada subintervalo $[t_{ i-1},t_i]$ para $i\in\natint{1,n}$.
            \item Decimos que $\gamma$ es suave en un subintervalo $[c,d]\subseteq[a,b]$ si $\gamma$ es diferenciable y tal que $\gamma'$ es continua en $[c,d]$.
        \end{itemize}
    \end{mydef}

    \begin{obs}
        Como es usual, decir que un camino $\gamma$ es diferenciable es decir que el límite:
        \begin{equation*}
            \lim_{ h\rightarrow0}\frac{\gamma(t+h)-\gamma(t)}{h}=\gamma'(t)
        \end{equation*}
        existe, para todo $a<t<b$ y, además, que los límites laterales correspondientes para $a$ y $b$ existen.
    \end{obs}

    Rápidamente se prueba el siguiente resultado que es clásico en integración de Lebesgue:

    \begin{lema}
        Un camino $\gamma$ es suave si y sólo si $\Re\gamma$ e $\Im\gamma$ son suaves.
    \end{lema}

    Supongamos que $\gamma$ es un camino suave y que para algún $t_0\in(a,b)$ se tiene que $\gamma'(t_0)\neq0$. Entonces, $\gamma$ tiene una línea tangente en el punto $z_0=\gamma(t_0)$.
    
    Esta línea pasa por el punto $z_0$ en la dirección de (el vector) $\gamma'(t_0)$.

    \begin{obs}
        En otras palabras, la pendiente de la recta tangente es $\tan\left(\arg\gamma'(t_0) \right)$.
    \end{obs}

    \begin{mydef}[\textbf{Ángulo entre Caminos que Intersectan}]
        Si $\gamma_1$ y $\gamma_2$ son dos caminos suaves con $\gamma_1=(t_1)=\gamma_2(t_2)=z_0$ con $\gamma_1'(t_1)\neq0$ y $\gamma_2'(t_2)\neq0$, se define el \textbf{ángulo entre los caminos $\gamma_1$ y $\gamma_2$ en el punto $z$} como:
        \begin{equation*}
            \arg\gamma_2'(t_2)-\arg(\gamma_1'(t_1))
        \end{equation*}
    \end{mydef}

    Resulta que las funciones analíticas preservan ángulos entre caminos:

    \begin{theor}
        Sea $\cf{f}{G}{\bbm{C}}$ una función analítica. Entonces, $f$ preserva ángulos en cada punto $z_0\in G$ tal que $f'(z_0)\neq0$.
    \end{theor}

    \begin{proof}
        Decir que preserva ángulos es equivalente a decir que si $\gamma_1$ y $\gamma_2$ son dos caminos suaves en $G$ tales que $\gamma_1(t_1)=\gamma_2(t_2)$ con $\gamma_1'(t_1)\neq0$ y $\gamma_2'(t_2)\neq0$, entonces el ángulo entre los caminos $\gamma_1$ y $\gamma_2$ en el punto $z_0=\gamma_1(t_1)=\gamma_2(t_2)$ es el mismo que el ángulo entre los caminos $f\circ\gamma_1$ y $f\circ\gamma_2$ en el punto $f(z_0)$. En otras palabras:
        \begin{equation*}
            \arg\gamma_2'(t_2)-\arg(\gamma_1'(t_1))=\arg (f\circ\gamma_2)'(t_2)-\arg(f\circ\gamma_1)'(t_1)
        \end{equation*}

        En efecto, tomemos ambos caminos como fueron descritos anteriormente. Para continuar, tomemos un camino $\gamma$ en $G$, consideremos $\cf{\sigma}{[a,b]}{\bbm{C}}$ dada por $\sigma=f\circ\gamma$. Se tiene que $\sigma$ es un camino suave, pues $f$ es analítica y $\gamma$ es un camino suave. Ahora, se verifica rápidamente la siguiente relación geométrica:
        \begin{equation*}
            \arg\sigma'(t_0)=\arg f'(\gamma(t_0))+\arg\gamma'(t_0)
        \end{equation*}
        siempre que $f'(\gamma(t_0))\neq0$ y $\gamma'(t_0)\neq0$, con $a<t_0<b$ (geométricamente esto significa que el ángulo se preserva bajo composición de una función analítica con un mapeo suave, esto se generaliza para composición de funciones analíticas). De esta relación se sigue, tomando los caminos $\gamma_1$ y $\gamma_2$, que:
        \begin{equation*}
            \arg\sigma_1'(t_1)-\arg\sigma_2'(t_2)=\arg\gamma_1'(t_1)-\arg\gamma_2'(t_2)
        \end{equation*}
        ya que en este caso $\gamma_1(t_1)=\gamma_2(t_2)$, tomando a $\sigma_i=f\circ\gamma_i$ para $i=1,2$. Sigue así que $f$ preserva ángulos.
    \end{proof}

    \begin{mydef}[\textbf{Funciones que Preservan Ángulos}]
        Decimos que una función $\cf{f}{G}{\bbm{C}}$ \textbf{preserva ángulos} si sucede lo descrito en el teorema anterior.
    \end{mydef}

    Esta propiedad de preservar ángulos resultará insuficiente para nuestros propósitos (por ahora), por lo cual introducimos una noción más fuerte que servirá más adelante:

    \begin{mydef}[\textbf{Mapeo Conforme}]
        Sea $\cf{f}{G}{\bbm{C}}$ una función que preserva ángulos. Si para todo $a\in G$ el límite:
        \begin{equation*}
            \lim_{ z\rightarrow a}\frac{\abs{f(z)-f(a)}}{z-a}
        \end{equation*}
        existe, diremos que $f$ es un \textbf{mapeo conforme}.
    \end{mydef}

    \begin{obs}
        Es claro que si $\cf{f}{G}{\bbm{C}}$ es analítica y $f'(z)\neq 0$ para todo $z\in G$, entonces $f$ es conforme. El converso resultará también ser cierto.
    \end{obs}

    \begin{exa}
        Si $f(z)=e^{z}$ para todo $z\in\bbm{C}$, entonces $f$ es conforme. En efecto, esto se sigue de la observación anterior. Dos cosas a notar de esta función son las siguientes:
        \begin{enumerate}[label = \textit{(\arabic*)}]
            \item $f$ mapea la línea $x=c$ a la circunferencia con centro en el origen y radio $e^c$.
            \item $f$ mapea la línea $y=d$ al rayo infinito $\left\{re^{ id}\Big|0<r<\infty\right\}$.
        \end{enumerate}
        Ahora, la rama del logarítmo $\log z$ hace lo opuesto a lo descrito anteriormente.
    \end{exa}

    Para continuar, veremos una clase de mapeos que son muy importantes (ver Grupos Fuchsianos):

    \begin{mydef}[\textbf{Transformaciones de Möbius}]
        Una función $S(z)=\frac{az+b}{cz+d}$ es llamada \textbf{transformación fraccional lineal}. Si $a,b,c$ y $d$ satisfacen además que:
        \begin{equation*}
            ad-bc\neq 0,
        \end{equation*}
        entonces $S$ es llamada una \textbf{transformación de Möbius}.
    \end{mydef}

    \begin{obs}
        Sea $S(z)=\frac{az+b}{cz+d}$, entonces $S$ está definida en $\bbm{C}\setminus\left\{-\frac{d}{c}\right\}$ si $c\neq0$. En caso contrario, está definida en todo $\bbm{C}$.

        Esta función tiene como inversa a la transformación:
        \begin{equation*}
            S^{-1}(z)=\frac{dz-b}{-cz+a}
        \end{equation*}
        y es tal que $S\circ S^{-1}(z)=S^{-1}\circ S(z)=z$ (siempre que estén definidas). También, si $S$ y $T$ son transformaciones fraccionales lineales, entonces $S\circ T$ también lo es.
    \end{obs}

    \begin{obs}[\textbf{Extensión a la Esfera de Riemann}]
        Ya se sabe que existe una biyección entre $\bbm{C}\cup\left\{\infty\right\}$ y $\bbm{S}^2$, por lo que ahora lo que haremos es considerar la \textbf{Esfera de Riemann} $\hat{\bbm{C}}=\bbm{C}\cup\left\{\infty\right\}$. Extendemos de forma natural una transformación de Möbius $T(z)=\frac{az+b}{cz+d}$ de $\hat{\bbm{C}}$ en $\hat{\bbm{C}}$ como sigue:
        \[
        T(z)=
        \begin{cases}
        \dfrac{az+b}{cz+d}, & z\neq -\dfrac{d}{c}, \\[1em]
        \infty, & z = -\dfrac{d}{c}, \\[1em]
        \begin{cases}
        \dfrac{a}{c}, & c\neq 0,\\[0.5em]
        \infty, & c = 0,
        \end{cases}
        & z=\infty .
        \end{cases}
        \]
        Esto hará que todas las transformaciones de Möbius se conviertan en mapeos biyectivos de $\hat{\bbm{C}}$ en $\hat{\bbm{C}}$. En particular, esto permitirá tomar a las transformaciones de Möbius como grupo dotado de la operación composición.
    \end{obs}

    De ahora en adelante consideraremos simplemente transformaciones de Möbius.

    \begin{exa}[\textbf{Transformaciones de Möbius no son Únicas}]
        Sea $S(z)=\frac{az+b}{cz+d}$ una transformación de Möbius. Si $\lambda$ es un núemero complejo no cero, se tiene que:
        \begin{equation*}
            S(z)=\frac{(\lambda a)z+(\lambda b)}{(\lambda c)z+(\lambda d)}
        \end{equation*}
        Esto es, los coeficientes $a,b,c$ y $d$ no son únicos.
    \end{exa}

    Cuatro transformaciones de Möbius importantísimas son las siguientes:
    \begin{enumerate}[label = \textit{(\arabic*)}]
        \item La función traslación: $T_a(z)=z+a$, con $a\in\bbm{C}$.
        \item La dilación: $D_a(z)=az$, con $a\in\bbm{C}\setminus\left\{0\right\}$.
        \item La rotación: $r_\vartheta(z)=e^{i\vartheta}z$ con $\vartheta\in[0,2\pi)$.
        \item La inversión: $I(z)=\frac{1}{z}$.
    \end{enumerate}
    
    \begin{obs}
        La rotación es un caso particular de una dilación.
    \end{obs}

    Estas transformaciones resultan relevantes ya que tenemos la siguiente proposición:

    \begin{propo}[\textbf{Descomposición de Transformaciones de Möbius}]
        Si $T$ es una transformación de Möbius, entonces $T$ es composición de traslaciones, dilaciones y de la inversión (puede que alguna falte).
    \end{propo}

    \begin{proof}
        Sea $T=\frac{az+b}{cz+d}$ una transformación de Möbius. Tenemos dos casos:
        \begin{itemize}
            \item Si $c=0$, entonces $T(z)=\left(\frac{a}{d}\right)z+\left(\frac{b}{d}\right)$, por lo que $T=T_{\frac{b}{d}}\circ D_{\frac{a}{d}}$.
            \item Si $c\neq 0$, entonces:
            \begin{equation*}
                T=T_{\frac{a}{c}}\circ D_{\frac{bc-ad}{c^2}}\circ I\circ T_{\frac{d}{c}}
            \end{equation*}
        \end{itemize}
    \end{proof}

    \begin{preg}
        ¿Cuáles son los puntos fijos de una transformación de Möbius?
    \end{preg}

    \begin{sol}
        Consideremos la transformación de Möbius $T(z)=\frac{az+b}{cz+d}$. Si $z_0\in\bbm{C}$ es un punto fijo, se tiene que:
        \begin{equation*}
            \begin{split}
                \frac{az_0+b}{cz_0+d}&=z_0\\
                \iff cz_0^2+(d-a)z_0-b=0
            \end{split}
        \end{equation*}
        Analicemos por casos:
        \begin{enumerate}[label = \textit{(\arabic*)}]
            \item Si $c\neq 0$, entonces $T$ tiene dos puntos fijos si el discriminante de la ecuación:
            \begin{equation*}
                cz^2+(d-a)z-b=0
            \end{equation*}
            es diferente de cero. En caso contrario tendrá un punto fijo.
            \item Si $c=0$, tenemos dos casos:
            \begin{enumerate}[label = \textit{(2.\arabic*)}]
                \item Si $a\neq d$, entonces tendremos dos puntos fijos, uno en $\bbm{C}$ y otro en $\infty$.
                \item Si $a=d$, tenemos dos casos:
                \begin{enumerate}[label = \textit{(2.2.\arabic*)}]
                    \item Si $b\neq 0$ solo habrá un punto fijo en $\infty$.
                    \item Si $b=0$, entonces $T=\bbm{1}_\bbm{C}$, por lo cual tendrá una cantidad infinita de puntos fijos.
                \end{enumerate}
            \end{enumerate}
        \end{enumerate}
    \end{sol}

\end{document}